<!DOCTYPE HTML>
<html lang="en" class="light" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>HDFS</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('light')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="start.html">前言</a></li><li class="chapter-item expanded "><a href="chapter_1.html"><strong aria-hidden="true">1.</strong> HDFS_shell</a></li><li class="chapter-item expanded "><a href="chapter_2.html"><strong aria-hidden="true">2.</strong> HDFS_java</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">HDFS</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="前言"><a class="header" href="#前言">前言</a></h1>
<p>本文档演示了大数据实验二的操作流程</p>
<p>文档中的<code>流程</code>说明了正常运行时需要的操作, 下面的<code>实机演示</code>演示了完整的操作流程</p>
<p>如有错漏, 直接搜微信号<code>Mouthree</code></p>
<p><strong>水平有限,仅供参考</strong></p>
<p><span style="color: hsl(0, 0%, 30%);">write by mouthree</span></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="hdfs_shell"><a class="header" href="#hdfs_shell">HDFS_shell</a></h1>
<h2 id="先开hadoop"><a class="header" href="#先开hadoop">先开Hadoop</a></h2>
<pre><code class="language-shell">cd /usr/local/hadoop
./sbin/start-dfs.sh
</code></pre>
<hr />
<h2 id="创建一个文件"><a class="header" href="#创建一个文件">创建一个文件</a></h2>
<pre><code class="language-shell">vim text.txt
</code></pre>
<p>按<code>i</code>输入, 之后按<code>ESC</code>退出编辑, 再之后输入<code>:wq</code>并<code>回车</code>保存并退出</p>
<hr />
<h2 id="在hdfs中创建一个文件夹"><a class="header" href="#在hdfs中创建一个文件夹">在HDFS中创建一个文件夹</a></h2>
<pre><code class="language-shell">hdfs dfs -mkdir -p /user/fileTest
</code></pre>
<p>之后输入<code>hdfs dfs -ls /user</code>来查看是否创建成功</p>
<p><img src="image.png" alt="alt text" /></p>
<hr />
<h2 id="解除文件权限限制"><a class="header" href="#解除文件权限限制">解除文件权限限制</a></h2>
<p>输入<code>hdfs dfs -chmod -R 777 /user/fileTest</code></p>
<hr />
<h2 id="在本地新建一个文件夹用来存shell脚本"><a class="header" href="#在本地新建一个文件夹用来存shell脚本">在本地新建一个文件夹用来存shell脚本</a></h2>
<pre><code class="language-shell">mkdir my_shell
</code></pre>
<hr />
<h2 id="1上传文件到hdfs-如果存在由用户指定追加还是覆盖"><a class="header" href="#1上传文件到hdfs-如果存在由用户指定追加还是覆盖"><code>(1)</code>上传文件到HDFS, 如果存在,由用户指定追加还是覆盖</a></h2>
<p>首先进入刚才的文件夹</p>
<pre><code class="language-shell">cd my_shell
</code></pre>
<p>创建一个shell脚本</p>
<pre><code class="language-shell">vim one.sh
</code></pre>
<p>进入之后输入如下内容</p>
<p><strong>注意</strong>:先按<code>i</code>进入输入模式再粘贴代码,粘贴之后按<code>esc</code>退出输入模式,之后输入<code>:wq</code>来保存并退出,之后每一道题的操作都一样,不再赘述</p>
<pre><code class="language-bash">#!/bin/bash
export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_162
export JRE_HOME=${JAVA_HOME}/jre
export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib
export PATH=${JAVA_HOME}/bin:$PATH
export PATH=$PATH:/usr/local/hadoop/bin:/usr/local/hadoop/sbin
my_dir="/user/fileTest/"
my_d="/usr/local/hadoop/"
read -p "input your file name: " my_file
if hdfs dfs -test -e "$my_dir/$my_file"; then
    echo "file already exists, what do you want to do: "
    read -p  "add/cover (a/c)" user_input
    if [ "$user_input" == "a" ]; then
        hdfs dfs -appendToFile "$my_d$my_file" "$my_dir$my_file"
        echo "add success"
    else
        hdfs dfs -copyFromLocal -f "$my_d$my_file" "$my_dir$my_file"
        echo "cover success"
    fi
else
    hdfs dfs -put "$my_d$my_file" "$my_dir"
    echo "put success"
fi
</code></pre>
<h3 id="流程"><a class="header" href="#流程">流程</a></h3>
<ol>
<li>
<p>输入<code>sudo bash one.sh</code></p>
</li>
<li>
<p>按照提示输入文件名<code>text.txt</code></p>
</li>
<li>
<p>如果是第一次上传,则会直接上传,否则按照提示选择追加还是覆写</p>
</li>
<li>
<p>操作两遍,把功能都试一下</p>
</li>
</ol>
<p><strong>注意</strong>:<code>text.txt</code>里面要写点东西,否则不显示内容</p>
<h3 id="实机演示"><a class="header" href="#实机演示">实机演示</a></h3>
<p><video controls src="one-1.mp4" title="Title"></video></p>
<hr />
<h2 id="2从hdfs上下载文件到本地如果重名则重命名再下载"><a class="header" href="#2从hdfs上下载文件到本地如果重名则重命名再下载"><code>(2)</code>从HDFS上下载文件到本地,如果重名则重命名再下载</a></h2>
<p>首先还是创建一个shell文件</p>
<pre><code class="language-shell">vim two.sh
</code></pre>
<p>直接开始写代码</p>
<pre><code class="language-bash">#!/bin/bash
export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_162
export JRE_HOME=${JAVA_HOME}/jre
export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib
export PATH=${JAVA_HOME}/bin:$PATH
export PATH=$PATH:/usr/local/hadoop/bin:/usr/local/hadoop/sbin
my_dir="/user/fileTest/"
my_local_dir="/usr/local/hadoop/"
hdfs dfs -ls /user/fileTest
echo " "
read -p "input the file you want: " my_file
if [ -f "/usr/local/hadoop/$my_file" ]; then
    echo "file is in here, to be remaned"
    my_file_name=$(echo "$my_file" | cut -d '.' -f 1)
    num=1
    while true; do
        if ! [ -f "/usr/local/hadoop/${my_file_name}_${num}.txt" ]; then
            hdfs dfs -get "/user/fileTest/$my_file" "/usr/local/hadoop/${my_file_name}_${num}.txt"
            echo "file ${my_file_name}_${num}.txt has been downloaded"
            break
        else
            let "num+=1"
        fi

        if [ $num -eq 10 ]; then
            echo "lock, num=$num"
            break
        fi
    done
else
    hdfs dfs -get "/user/fileTest/$my_file" "$my_local_dir$my_file"
    echo "file $my_local_dir$my_file has been downloaded"
fi

</code></pre>
<h3 id="流程-1"><a class="header" href="#流程-1">流程</a></h3>
<ol>
<li>
<p>输入<code>sudo bash two.sh</code>开始运行</p>
</li>
<li>
<p>代码在刚开始运行的时候会显示当前目录有哪些文件可以复制</p>
</li>
<li>
<p>输入文件,由于我们要复制text这个文件,所以直接输入<code>text.txt</code></p>
</li>
<li>
<p>程序会检查是否有相同名字的文件,如果有则直接新建,没有就会自动新建一个命名格式为<code>{fileName}{x}.txt</code>的文件</p>
</li>
<li>
<p><strong>之后运行三次得到正确结果</strong></p>
</li>
</ol>
<h3 id="实机演示-1"><a class="header" href="#实机演示-1">实机演示</a></h3>
<p><video controls src="two-2.mp4" title="Title"></video></p>
<hr />
<h2 id="3将hdfs中指定文件的内容输出到终端中"><a class="header" href="#3将hdfs中指定文件的内容输出到终端中"><code>(3)</code>将HDFS中指定文件的内容输出到终端中</a></h2>
<p>直接输入<code>hdfs dfs -cat /user/fileTest/text.txt</code></p>
<h3 id="实机演示-2"><a class="header" href="#实机演示-2">实机演示</a></h3>
<p><video controls src="one.mp4" title="Title"></video></p>
<hr />
<h2 id="4显示hdfs中指定的文件的读写权限大小创建时间路径等"><a class="header" href="#4显示hdfs中指定的文件的读写权限大小创建时间路径等"><code>(4)</code>显示HDFS中指定的文件的读写权限、大小、创建时间、路径等</a></h2>
<p>直接输入<code>hdfs dfs -ls -r /user/fileTest/text.txt</code></p>
<p><img src="image-4.png" alt="alt text" /></p>
<hr />
<h2 id="5给定hdfs中某一个目录输出该目录下的所有文件的读写权限大小创建时间路径等信息如果该文件是目录则递归输出该目录下所有文件相关信息"><a class="header" href="#5给定hdfs中某一个目录输出该目录下的所有文件的读写权限大小创建时间路径等信息如果该文件是目录则递归输出该目录下所有文件相关信息"><code>(5)</code>给定HDFS中某一个目录，输出该目录下的所有文件的读写权限、大小、创建时间、路径等信息，如果该文件是目录，则递归输出该目录下所有文件相关信息</a></h2>
<p>直接输入<code>hdfs dfs -ls -R /user</code></p>
<p><img src="1a4082bae900ec4f48575757b4825aa.png" alt="alt text" /></p>
<hr />
<h2 id="6提供文件路径对其创建或删除创建时自动创建路径"><a class="header" href="#6提供文件路径对其创建或删除创建时自动创建路径"><code>(6)</code>提供文件路径,对其创建或删除,创建时自动创建路径</a></h2>
<p>创建shell文件</p>
<pre><code class="language-shell">cd /usr/local/hadoop/my_shell
vim six.sh
</code></pre>
<p>直接写文件</p>
<pre><code class="language-bash">#!/bin/bash
export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_162
export JRE_HOME=${JAVA_HOME}/jre
export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib
export PATH=${JAVA_HOME}/bin:$PATH
export PATH=$PATH:/usr/local/hadoop/bin:/usr/local/hadoop/sbin
read -p "input path(only path): " op_path
read -p "input file: " file_path
read -p "create or delete(c / d): " t
if [ "$t" == "c" ]; then
    if hdfs dfs -test -e "$op_path"; then
        if hdfs dfs -test -e "$op_path/$file_path"; then
            echo "file already exists"
        else
            hdfs dfs -touchz "$op_path/$file_path"
            echo "ok"
        fi
    else
        hdfs dfs -mkdir $op_path
        hdfs dfs -touchz "$op_path/$file_path"
        echo "ok"
    fi
else
    if hdfs dfs -test -e "$op_path/$file_path"; then
        hdfs dfs -rm "$op_path/$file_path"
        echo "ok"
    else
        echo "no file"
    fi
fi
</code></pre>
<h3 id="流程-2"><a class="header" href="#流程-2">流程</a></h3>
<ol>
<li>
<p>输入<code>sudo bash six.sh</code>运行脚本</p>
</li>
<li>
<p>按照提示依次输入<code>文件夹</code>,<code>文件名</code>,<code>操作</code></p>
</li>
<li>
<p>等待运行结束</p>
</li>
<li>
<p>输入<code>hdfs dfs -ls -R /user</code>来查看操作是否成功</p>
</li>
</ol>
<h3 id="实机演示-3"><a class="header" href="#实机演示-3">实机演示</a></h3>
<p><video controls src="six.mp4" title="Title"></video></p>
<hr />
<h2 id="7hdfs创建或删除目录创建时如果没有就自动新建删除时如果目录不为空则问用户"><a class="header" href="#7hdfs创建或删除目录创建时如果没有就自动新建删除时如果目录不为空则问用户"><code>(7)</code>HDFS创建或删除目录,创建时如果没有就自动新建,删除时如果目录不为空则问用户</a></h2>
<pre><code class="language-shell">cd /usr/local/hadoop/my_shell
vim seven.sh
</code></pre>
<p>输入代码</p>
<pre><code class="language-bash">#!/bin/bash
export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_162
export JRE_HOME=${JAVA_HOME}/jre
export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib
export PATH=${JAVA_HOME}/bin:$PATH
export PATH=$PATH:/usr/local/hadoop/bin:/usr/local/hadoop/sbin
read -p "input path: " op_path
read -p "delete or create(d/c): " my_op
if [ "$my_op" == "d" ]; then
    if hdfs dfs -test -e "$op_path"; then
        hdfs_output=$(hdfs dfs -du -s "$op_path")
        if [ "$hdfs_output" != "0  0  $op_path" ]; then
            read -p "file is not empty, do you want to delete it?(y/n): " my_opp
            if [ "$my_opp" == "y" ]; then
                hdfs dfs -rm -r "$op_path"
                echo "successfully delete"
            else
                echo "ok"
            fi
        else
            hdfs dfs -rm -r "$op_path"
            echo "successfully delete"
        fi
    else
        echo "no dir"
    fi
else
    if hdfs dfs -test -e "$op_path"; then
        echo "create failed, already have folder"
    else
        hdfs dfs -mkdir $op_path
        echo "create successfully"
    fi
fi
</code></pre>
<p>以上代码实现了创建文件夹,删除文件夹,同名文件夹检测,空文件夹检测</p>
<h3 id="流程-3"><a class="header" href="#流程-3">流程</a></h3>
<ol>
<li>
<p>输入<code>sudo bash seven.sh</code>运行脚本</p>
</li>
<li>
<p>输入要操作的<code>HDFS文件</code>的路径</p>
</li>
<li>
<p>选择要进行什么操作</p>
</li>
<li>
<p>多进行几次,尝试每一个可能的结果</p>
<p>(1)创建文件夹,然后删除</p>
<p>(2)创建文件夹,然后再次创建一个同名文件夹,查看结果</p>
<p>(3)创建文件夹,向文件夹中填入文件, 删除文件夹,查看结果</p>
</li>
<li>
<p>具体操作方式参考下方实机演示</p>
</li>
</ol>
<h3 id="实机演示-4"><a class="header" href="#实机演示-4">实机演示</a></h3>
<p><video controls src="seven.mp4" title="Title"></video></p>
<hr />
<h2 id="8向hdfs中指定文件追加内容由用户指定内容追加到原有文件开头或结尾"><a class="header" href="#8向hdfs中指定文件追加内容由用户指定内容追加到原有文件开头或结尾"><code>(8)</code>向HDFS中指定文件追加内容，由用户指定内容追加到原有文件开头或结尾</a></h2>
<pre><code class="language-shell">cd /usr/local/hadoop/my_shell
vim eight.sh
</code></pre>
<p>代码</p>
<pre><code class="language-bash">#!/bin/bash
export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_162
export JRE_HOME=${JAVA_HOME}/jre
export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib
export PATH=${JAVA_HOME}/bin:$PATH
export PATH=$PATH:/usr/local/hadoop/bin:/usr/local/hadoop/sbin
read -p "input path: " op_path
read -p "input filename: " my_file
if hdfs dfs -test -e "$op_path/$my_file"; then
    read -p "input insert path: " in_filepath
    read -p "input insert file: " in_file
    read -p "head or tail(h/t): " t
    if [ "$t" == "h" ]; then
        hdfs dfs -put "$in_filepath/$in_file" "$op_path"
        hdfs dfs -get "$op_path/$my_file" "/usr/local/hadoop/mouthree.txt"
        hdfs dfs -appendToFile "/usr/local/hadoop/mouthree.txt" "$op_path/$in_file"
        hdfs dfs -rm "$op_path/$my_file"
        hdfs dfs -mv "$op_path/$in_file" "$op_path/$my_file"
        rm "/usr/local/hadoop/mouthree.txt"
        echo "ok"
    else
        hdfs dfs -appendToFile "$in_filepath/$in_file" "$op_path/$my_file"
        echo "ok"
    fi
else
    echo "no file"
fi
</code></pre>
<h3 id="流程-4"><a class="header" href="#流程-4">流程</a></h3>
<ol>
<li>
<p>在<code>/usr/local/hadoop/my_shell</code>文件夹中创建一个文件用来插入<code>vim e.txt</code>,随意赋值</p>
</li>
<li>
<p>再次创建一个文件<code>vim E.txt</code>输入值并上传到HDFS中<code>hdfs dfs -put E.txt /user/fileTest</code>,这个文件就是被插入的</p>
</li>
<li>
<p>运行脚本, 按照提示依次输入,查看结果</p>
</li>
</ol>
<h3 id="实机演示-5"><a class="header" href="#实机演示-5">实机演示</a></h3>
<p><video controls src="eight.mp4" title="Title"></video></p>
<hr />
<h2 id="9删除hdfs中指定的文件"><a class="header" href="#9删除hdfs中指定的文件"><code>(9)</code>删除HDFS中指定的文件</a></h2>
<p>由于咱们第八题的文件还没删除,所以接着上面继续</p>
<p>可以输入<code>hdfs dfs -ls -R -h /user/fileTest</code>来查看是不是还在</p>
<p>如果不在,可以使用<code>hdfs dfs -put E.txt /user/fileTest</code>上传</p>
<pre><code class="language-shell">cd /usr/local/hadoop/my_shell
hdfs dfs -rm /user/fileTest/E.txt
hdfs dfs -ls -R -h /user/fileTest
</code></pre>
<p>输入之后,可以看到文件已经被成功删除</p>
<p><img src="192f2424d3a5b425de783d4bf452063.png" alt="alt text" /></p>
<hr />
<h2 id="10删除hdfs中指定目录由用户指定目录中如果存在文件时是否删除目录"><a class="header" href="#10删除hdfs中指定目录由用户指定目录中如果存在文件时是否删除目录"><code>(10)</code>删除HDFS中指定目录，由用户指定目录中如果存在文件时是否删除目录</a></h2>
<pre><code class="language-shell">cd /usr/local/hadoop/my_shell
vim ten.sh
</code></pre>
<p>代码</p>
<pre><code class="language-bash">#!/bin/bash
export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_162
export JRE_HOME=${JAVA_HOME}/jre
export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib
export PATH=${JAVA_HOME}/bin:$PATH
export PATH=$PATH:/usr/local/hadoop/bin:/usr/local/hadoop/sbin
read -p "input path: " op_path
if hdfs dfs -test -e "$op_path"; then
        hdfs_output=$(hdfs dfs -du -s "$op_path")
        if [ "$hdfs_output" != "0  0  $op_path" ]; then
            read -p "file is not empty, do you want to delete it?(y/n): " my_opp
            if [ "$my_opp" == "y" ]; then
                hdfs dfs -rm -r "$op_path"
                echo "successfully delete"
            else
                echo "ok"
            fi
        else
            hdfs dfs -rm -r "$op_path"
            echo "successfully delete"
        fi
    else
        echo "no dir"
    fi
</code></pre>
<h3 id="流程-5"><a class="header" href="#流程-5">流程</a></h3>
<ol>
<li>
<p>在HDFS中创建一个文件夹<code>hdfs dfs -mkdir /user/fileTest/yeah</code></p>
</li>
<li>
<p>解除一下权限限制<code>hdfs dfs -chmod -R 777 /user/fileTest</code></p>
</li>
<li>
<p>上传一个有信息的文件到那个文件夹<code>hdfs dfs -put e.txt /user/fileTest/yeah</code></p>
</li>
<li>
<p>运行脚本,按照提示操作,操作两次验证所有结果</p>
</li>
</ol>
<h3 id="实机演示-6"><a class="header" href="#实机演示-6">实机演示</a></h3>
<p><video controls src="ten.mp4" title="Title"></video></p>
<hr />
<h2 id="11在hdfs中将文件从源路径移动到目的路径"><a class="header" href="#11在hdfs中将文件从源路径移动到目的路径"><code>(11)</code>在HDFS中，将文件从源路径移动到目的路径</a></h2>
<p>创建一个文件夹,输入<code>hdfs dfs -mkdir /user/fileTest/yeah</code></p>
<p>上传一个文件到<code>/user/fileTest</code>文件夹<code>hdfs dfs -put E.txt /user/fileTest/yeah</code></p>
<p>输入<code>hdfs dfs -ls -R -h /user/fileTest</code>查看当前文件夹内文件分布</p>
<h3 id="实机演示-7"><a class="header" href="#实机演示-7">实机演示</a></h3>
<p><video controls src="eleven.mp4" title=""></video></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="hdfs_java"><a class="header" href="#hdfs_java">HDFS_java</a></h1>
<h2 id="先开hadoop-1"><a class="header" href="#先开hadoop-1">先开Hadoop</a></h2>
<pre><code class="language-shell">cd /usr/local/hadoop
./sbin/start-dfs.sh #启动hadoop
</code></pre>
<h2 id="之后在本地再新建一个文件"><a class="header" href="#之后在本地再新建一个文件">之后在本地再新建一个文件</a></h2>
<pre><code class="language-shell">vim hdfs_java.txt
</code></pre>
<p>进入之后按<code>i</code>开始编辑, 按<code>esc</code>退出编辑, 输入<code>:wq</code>保存并退出</p>
<hr />
<h2 id="1向hdfs中存入文件如果有则选择追加还是覆盖"><a class="header" href="#1向hdfs中存入文件如果有则选择追加还是覆盖"><code>(1)</code>向HDFS中存入文件,如果有则选择追加还是覆盖</a></h2>
<p>进入eclipse</p>
<pre><code class="language-shell">cd /usr/local/eclipse
./eclipse 
</code></pre>
<h2 id="点击查看如何新建项目"><a class="header" href="#点击查看如何新建项目"><a href="chapter_2.html#%E5%85%B3%E4%BA%8E%E5%A6%82%E4%BD%95%E5%88%9B%E5%BB%BAhdfs%E9%A1%B9%E7%9B%AE">点击查看如何新建项目</a></a></h2>
<p>在项目中写入如下代码</p>
<pre><code class="language-java">import java.io.IOException;
import java.util.Scanner;
import org.apache.hadoop.fs.FSDataOutputStream;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import java.io.FileReader;
import java.io.BufferedReader;

public class one {
	public static void main(String[] args) throws Exception {
		Scanner scanner = new Scanner(System.in);
		System.out.println("input local address");
		String file_address = scanner.nextLine();
		System.out.println("input file name");
		String file_name = scanner.nextLine();
		System.out.println("input folder address");
		String folder_address = scanner.nextLine();
		one m = new one();
		m.upload_file(file_address, file_name, folder_address);
		scanner.close();
	}
	
	public void upload_file(String file_address, String file_name, String folder_address) throws Exception {
		Configuration conf = new Configuration();
		conf.set("fs.defaultFS","hdfs://localhost:9000");
        conf.set("fs.hdfs.impl","org.apache.hadoop.hdfs.DistributedFileSystem");
        conf.set("dfs.client.block.write.replace-datanode-on-failure.policy", "NEVER");
        conf.setBoolean("dfs.client.block.write.replace-datanode-on-failure.enable", true);
        FileSystem fs = FileSystem.get(conf);
        Path local_file = new Path(file_address + "/" + file_name);
        Path over_file = new Path(folder_address);
        
        if (fs.exists(new Path(folder_address + "/" + file_name))) {
            System.out.println("The file is already there");
            System.out.println("Choose append or overwrite  |  (a, o)");
            Scanner scanner = new Scanner(System.in);
            String t = scanner.nextLine();
            if(t.equals("a")) {
            	BufferedReader br = null;
            	FSDataOutputStream out = fs.append(new Path(folder_address + "/" + file_name));
            	br = new BufferedReader(new FileReader(file_address + "/" + file_name));
                String line;
                while ((line = br.readLine()) != null) {
                    out.writeBytes(line + "\n");
                }
                out.close();
                br.close();
                System.out.println("successfully append");
            }else if(t.equals("o")) {
            	fs.copyFromLocalFile(local_file, over_file);
            	System.out.println("successfully overwrite");
            }
            scanner.close();
        } else {
        	fs.copyFromLocalFile(local_file, over_file);
        	System.out.println("OK");
        }
        fs.close();
	}
}
</code></pre>
<h3 id="流程-6"><a class="header" href="#流程-6">流程</a></h3>
<ol>
<li>
<p>首先输入要<code>上传的文件</code>的<code>本地路径</code></p>
</li>
<li>
<p>接着输入要上传的文件名, 要带后缀</p>
</li>
<li>
<p>最后输入要传入的hdfs的路径</p>
</li>
<li>
<p>新开一个命令行窗口, <em>直接右键之前打开的,然后点击新建即可</em></p>
</li>
<li>
<p>输入<code>cd /usr/local/hadoop</code>进入hadoop文件夹, 接着输入<code>hdfs dfs -cat /user/fileTest/hdfs_java.txt</code>来查看操作是否成功,成功了则会显示文件内容</p>
</li>
<li>
<p>第一次上传会直接结束,再次运行程序会提示覆盖还是追加,根据文本提示操作</p>
</li>
</ol>
<h3 id="实机演示-8"><a class="header" href="#实机演示-8">实机演示</a></h3>
<p><video controls src="hdfs_1.mp4" title="Title"></video></p>
<h3 id="代码详解"><a class="header" href="#代码详解"><a href="">代码详解</a></a></h3>
<hr />
<h2 id="2从hdfs上下载文件到本地如果重名则重命名再下载-1"><a class="header" href="#2从hdfs上下载文件到本地如果重名则重命名再下载-1"><code>(2)</code>从HDFS上下载文件到本地,如果重名则重命名再下载</a></h2>
<p>首先创建文件二</p>
<p>输入如下代码</p>
<pre><code class="language-java">import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import java.io.BufferedOutputStream;
import java.io.FileOutputStream;
import java.io.IOException;
import java.io.InputStream;
import java.io.OutputStream;
import java.util.Scanner;
import java.nio.file.Files;
import java.nio.file.Paths;
public class two {
	public static void main(String[] args) throws Exception {
		Scanner scanner = new Scanner(System.in);
		System.out.println("input folder address");
		String folder_address = scanner.nextLine();
		System.out.println("input file name");
		String file_name = scanner.nextLine();
		System.out.println("input local address");
		String file_address = scanner.nextLine();
		two m = new two();
		m.download_file_local(file_address, file_name, folder_address);
		scanner.close();
	}
	
	public void download_file_local(String file_address, String file_name, String folder_address) throws Exception {
		Configuration conf = new Configuration();
		conf.set("fs.defaultFS","hdfs://localhost:9000");
        conf.set("fs.hdfs.impl","org.apache.hadoop.hdfs.DistributedFileSystem");
        conf.set("dfs.client.block.write.replace-datanode-on-failure.policy", "NEVER");
        conf.setBoolean("dfs.client.block.write.replace-datanode-on-failure.enable", true);
        FileSystem fs = FileSystem.get(conf);
        Path local_address = new Path(file_address);
        Path hdfs_file = new Path(folder_address + "/" + file_name);
        if(Files.exists(Paths.get(file_address + "/" + file_name))) {
        	System.out.println("The file is already there");
        	System.out.println("input new file name");
        	Scanner scanner = new Scanner(System.in);
        	String new_file_name = scanner.nextLine();
        	Path new_local = new Path(file_address + "/" + new_file_name);
        	fs.copyToLocalFile(false, hdfs_file, new_local, true);
        	scanner.close();
        	System.out.println("successfully download");
        }else {
        	fs.copyToLocalFile(false, hdfs_file, local_address, true);
        	System.out.println("OK");
        }
	}
}
</code></pre>
<h3 id="流程-7"><a class="header" href="#流程-7">流程</a></h3>
<ol>
<li>
<p>在上一部新建的命令行窗口中输入<code>rm -f hdfs_java.txt</code>来删除之前创建的文件,由于在实验一中我们上传了一个文件到hdfs中,所以不用担心文件没了</p>
</li>
<li>
<p>输入<code>ls</code>查看是否删除成功</p>
</li>
<li>
<p>首先输入要下载的文件在hdfs中的文件夹</p>
</li>
<li>
<p>输入要下载到本地的文件名</p>
</li>
<li>
<p>输入要下载到本地的路径</p>
</li>
<li>
<p>再次来到之前新建的命令行窗口中,输入<code>ls</code>查看本地文件内容是否下载成功</p>
</li>
<li>
<p>再次运行代码, 根据提示输入新的文件名,再次按照<code>上一步</code>操作,可以看到重命名的文件</p>
</li>
</ol>
<h3 id="实机演示-9"><a class="header" href="#实机演示-9">实机演示</a></h3>
<p><video controls src="hdfs_2.mp4" title="Title"></video></p>
<h3 id="代码详解-1"><a class="header" href="#代码详解-1"><a href="">代码详解</a></a></h3>
<hr />
<h2 id="3将hdfs中指定文件的内容输出到终端中-1"><a class="header" href="#3将hdfs中指定文件的内容输出到终端中-1"><code>(3)</code>将HDFS中指定文件的内容输出到终端中</a></h2>
<pre><code class="language-java">import java.util.Scanner;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import java.io.BufferedReader;
import org.apache.hadoop.fs.FSDataInputStream;
import java.io.InputStreamReader;
public class three {
	public static void main(String[] args) throws Exception {
		System.out.println("input hdfs file address");
		Scanner scanner = new Scanner(System.in);
		String hdfsFilePath = scanner.nextLine();
		Configuration conf = new Configuration();
		conf.set("fs.defaultFS","hdfs://localhost:9000");
        conf.set("fs.hdfs.impl","org.apache.hadoop.hdfs.DistributedFileSystem");
        conf.set("dfs.client.block.write.replace-datanode-on-failure.policy", "NEVER");
        conf.setBoolean("dfs.client.block.write.replace-datanode-on-failure.enable", true);
        FileSystem fs = FileSystem.get(conf);
        Path hdfsPath = new Path(hdfsFilePath);
        FSDataInputStream in = fs.open(hdfsPath);
        BufferedReader br = new BufferedReader(new InputStreamReader(in));
        String line;
        while ((line = br.readLine()) != null) {
        	System.out.println(line);
        }
        br.close();
        in.close();
        System.out.println("");
        System.out.println("----------------------");
        System.out.println("successfully out");
        scanner.close();
	}
}
</code></pre>
<h3 id="流程-8"><a class="header" href="#流程-8">流程</a></h3>
<ol>
<li>
<p>按照提示输入要显示的文件在hdfs中的路径</p>
</li>
<li>
<p>直接运行即可</p>
</li>
</ol>
<h3 id="实机演示-10"><a class="header" href="#实机演示-10">实机演示</a></h3>
<p><video controls src="hdfs_3.mp4" title="Title"></video></p>
<h3 id="代码详解-2"><a class="header" href="#代码详解-2"><a href="">代码详解</a></a></h3>
<hr />
<h2 id="4显示hdfs中指定的文件的读写权限大小创建时间路径等-1"><a class="header" href="#4显示hdfs中指定的文件的读写权限大小创建时间路径等-1"><code>(4)</code>显示HDFS中指定的文件的读写权限、大小、创建时间、路径等</a></h2>
<pre><code class="language-java">import java.util.Scanner;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.fs.FileStatus;
public class four {
	public static void main(String[] args) throws Exception {
		System.out.println("input hdfs file address");
		Scanner scanner = new Scanner(System.in);
		String hdfsFilePath = scanner.nextLine();
		Configuration conf = new Configuration();
		conf.set("fs.defaultFS","hdfs://localhost:9000");
        conf.set("fs.hdfs.impl","org.apache.hadoop.hdfs.DistributedFileSystem");
        conf.set("dfs.client.block.write.replace-datanode-on-failure.policy", "NEVER");
        conf.setBoolean("dfs.client.block.write.replace-datanode-on-failure.enable", true);
        FileSystem fs = FileSystem.get(conf);
        Path hdfsPath = new Path(hdfsFilePath);
        FileStatus fileStatus = fs.getFileStatus(hdfsPath);
        System.out.println("file address: " + fileStatus.getPath());
        System.out.println("file size: " + fileStatus.getLen() + " 字节");
        System.out.println("block size: " + fileStatus.getBlockSize() + " 字节");
        System.out.println("number of copies: " + fileStatus.getReplication());
        System.out.println("user: " + fileStatus.getOwner());
        System.out.println("grouping: " + fileStatus.getGroup());
        System.out.println("permission: " + fileStatus.getPermission());
        System.out.println("change time: " + fileStatus.getModificationTime());
        System.out.println("visit time: " + fileStatus.getAccessTime());
        scanner.close();
	}
}

</code></pre>
<h3 id="流程-9"><a class="header" href="#流程-9">流程</a></h3>
<ol>
<li>按照提示输入要显示的文件在hdfs中的路径</li>
</ol>
<h3 id="实机演示-11"><a class="header" href="#实机演示-11">实机演示</a></h3>
<p><video controls src="hdfs_4.mp4" title="Title"></video></p>
<h3 id="代码详解-3"><a class="header" href="#代码详解-3"><a href="">代码详解</a></a></h3>
<hr />
<h2 id="5给定hdfs中某一个目录输出该目录下的所有文件的读写权限大小创建时间路径等信息如果该文件是目录则递归输出该目录下所有文件相关信息-1"><a class="header" href="#5给定hdfs中某一个目录输出该目录下的所有文件的读写权限大小创建时间路径等信息如果该文件是目录则递归输出该目录下所有文件相关信息-1"><code>(5)</code>给定HDFS中某一个目录，输出该目录下的所有文件的读写权限、大小、创建时间、路径等信息，如果该文件是目录，则递归输出该目录下所有文件相关信息</a></h2>
<pre><code class="language-java">import java.util.Scanner;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.fs.FileStatus;
public class five {
	public static void main(String[] args) throws Exception {
		System.out.println("input hdfs file address");
		Scanner scanner = new Scanner(System.in);
		String hdfsFilePath = scanner.nextLine();
		Configuration conf = new Configuration();
		conf.set("fs.defaultFS","hdfs://localhost:9000");
        conf.set("fs.hdfs.impl","org.apache.hadoop.hdfs.DistributedFileSystem");
        conf.set("dfs.client.block.write.replace-datanode-on-failure.policy", "NEVER");
        conf.setBoolean("dfs.client.block.write.replace-datanode-on-failure.enable", true);
        FileSystem fs = FileSystem.get(conf);
        Path hdfsPath = new Path(hdfsFilePath);
        FileStatus[] fileStatuses = fs.listStatus(hdfsPath);
        for (FileStatus fileStatus : fileStatuses) {
	        System.out.println("file address: " + fileStatus.getPath());
	        System.out.println("file size: " + fileStatus.getLen() + " 字节");
	        System.out.println("block size: " + fileStatus.getBlockSize() + " 字节");
	        System.out.println("number of copies: " + fileStatus.getReplication());
	        System.out.println("user: " + fileStatus.getOwner());
	        System.out.println("grouping: " + fileStatus.getGroup());
	        System.out.println("permission: " + fileStatus.getPermission());
	        System.out.println("change time: " + fileStatus.getModificationTime());
	        System.out.println("visit time: " + fileStatus.getAccessTime());
	        System.out.println("");
	        System.out.println("---------------------");
	        System.out.println("");
        }
        scanner.close();
	}
}
</code></pre>
<h3 id="流程-10"><a class="header" href="#流程-10">流程</a></h3>
<ol>
<li>按照提示输入文件夹路径</li>
</ol>
<h3 id="实机演示-12"><a class="header" href="#实机演示-12">实机演示</a></h3>
<p><video controls src="hdfs_5.mp4" title="Title"></video></p>
<h3 id="代码详解-4"><a class="header" href="#代码详解-4"><a href="">代码详解</a></a></h3>
<hr />
<h2 id="6提供文件路径对其创建或删除创建时自动创建路径-1"><a class="header" href="#6提供文件路径对其创建或删除创建时自动创建路径-1"><code>(6)</code>提供文件路径,对其创建或删除,创建时自动创建路径</a></h2>
<pre><code class="language-java">import java.util.Scanner;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;

public class six {
	public static void main(String[] args) throws Exception {
		System.out.println("input hdfs file address");
		Scanner scanner = new Scanner(System.in);
		String hdfsFilePath = scanner.nextLine();
		Configuration conf = new Configuration();
		conf.set("fs.defaultFS","hdfs://localhost:9000");
        conf.set("fs.hdfs.impl","org.apache.hadoop.hdfs.DistributedFileSystem");
        conf.set("dfs.client.block.write.replace-datanode-on-failure.policy", "NEVER");
        conf.setBoolean("dfs.client.block.write.replace-datanode-on-failure.enable", true);
        FileSystem fs = FileSystem.get(conf);
        Path file_address = new Path(hdfsFilePath);
        System.out.println("delete or create | (d/c)");
        String input_choose = scanner.nextLine();
        if(input_choose.equals("d")) {
        	if(fs.exists(new Path(hdfsFilePath))) {
        		fs.delete(file_address, true);
        		System.out.println("successfully delete");
        	}else {
        		System.out.println("no file");
        	}
        }else if(input_choose.equals("c")) {
        	fs.create(file_address, true, fs.getConf().getInt("io.file.buffer.size", 4096));
        	System.out.println("OK");
        }
        scanner.close();
	}
}
</code></pre>
<h3 id="流程-11"><a class="header" href="#流程-11">流程</a></h3>
<ol>
<li>按照提示输入<strong>hdfs</strong>中的文件路径,根据文本提示操作</li>
</ol>
<h3 id="实机演示-13"><a class="header" href="#实机演示-13">实机演示</a></h3>
<p><video controls src="hdfs_6-1.mp4" title="Title"></video></p>
<h3 id="代码详解-5"><a class="header" href="#代码详解-5"><a href="">代码详解</a></a></h3>
<hr />
<h2 id="7hdfs创建或删除目录创建时如果没有就自动新建删除时如果目录不为空则问用户-1"><a class="header" href="#7hdfs创建或删除目录创建时如果没有就自动新建删除时如果目录不为空则问用户-1"><code>(7)</code>HDFS创建或删除目录,创建时如果没有就自动新建,删除时如果目录不为空则问用户</a></h2>
<pre><code class="language-java">import java.util.Scanner;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.fs.FileStatus;

public class seven {
	public static void main(String[] args) throws Exception {
		System.out.println("input hdfs file address");
		Scanner scanner = new Scanner(System.in);
		String hdfsFilePath = scanner.nextLine();
		Configuration conf = new Configuration();
		conf.set("fs.defaultFS","hdfs://localhost:9000");
        conf.set("fs.hdfs.impl","org.apache.hadoop.hdfs.DistributedFileSystem");
        conf.set("dfs.client.block.write.replace-datanode-on-failure.policy", "NEVER");
        conf.setBoolean("dfs.client.block.write.replace-datanode-on-failure.enable", true);
        FileSystem fs = FileSystem.get(conf);
        Path file_address = new Path(hdfsFilePath);
        System.out.println("delete or create | (d/c)");
        String input_choose = scanner.nextLine();
        if(input_choose.equals("d")) {
        	if(fs.exists(new Path(hdfsFilePath))) {
        		FileStatus[] fileStatuses = fs.listStatus(file_address);
        		if(fileStatuses.length == 0) {
        			fs.delete(file_address, true);
        			System.out.println("successfully delete");
        		}else {
        			System.out.println("This folder is not empty, do you want to delete? (y/n)");
        			String t = scanner.nextLine();
        			if(t.equals("y")) {
        				fs.delete(file_address, true);
        				System.out.println("successfully delete");
        			}else {
        				System.out.println("OK");
        			}
        		}
        	}else {
        		System.out.println("no file");
        	}
        }else if(input_choose.equals("c")) {
        	fs.create(file_address, true, fs.getConf().getInt("io.file.buffer.size", 4096));
        	System.out.println("OK");
        }
        scanner.close();
	}
}

</code></pre>
<h3 id="流程-12"><a class="header" href="#流程-12">流程</a></h3>
<ol start="0">
<li>懒得写了,直接看<code>实机演示</code>, 后面的几个也都一样</li>
</ol>
<h3 id="实机演示-14"><a class="header" href="#实机演示-14">实机演示</a></h3>
<p><video controls src="HDFS_7.mp4" title="Title"></video></p>
<h3 id="代码详解-6"><a class="header" href="#代码详解-6"><a href="">代码详解</a></a></h3>
<hr />
<h2 id="8向hdfs中指定文件追加内容由用户指定内容追加到原有文件开头或结尾-1"><a class="header" href="#8向hdfs中指定文件追加内容由用户指定内容追加到原有文件开头或结尾-1"><code>(8)</code>向HDFS中指定文件追加内容，由用户指定内容追加到原有文件开头或结尾</a></h2>
<pre><code class="language-java">import java.util.Scanner;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import java.io.OutputStream;
import java.io.BufferedReader;
import java.io.InputStreamReader;
import org.apache.hadoop.io.IOUtils;
public class eight {
	public static void main(String[] args) throws Exception {
		System.out.println("input hdfs file address");
		Scanner scanner = new Scanner(System.in);
		String hdfsFilePath = scanner.nextLine();
		Configuration conf = new Configuration();
		conf.set("fs.defaultFS","hdfs://localhost:9000");
        conf.set("fs.hdfs.impl","org.apache.hadoop.hdfs.DistributedFileSystem");
        conf.set("dfs.client.block.write.replace-datanode-on-failure.policy", "NEVER");
        conf.setBoolean("dfs.client.block.write.replace-datanode-on-failure.enable", true);
        FileSystem fs = FileSystem.get(conf);
        Path file_address = new Path(hdfsFilePath);
        if(fs.exists(new Path(hdfsFilePath))) {
        	System.out.println("add head or tail | (h/t)");
        	String t = scanner.nextLine();
        	if(t.equals("h")) {
        		System.out.println("input what you want add");
        		String a = scanner.nextLine();
        		OutputStream out = fs.create(new Path(hdfsFilePath.replace(".", "_mouthree" + ".")));
        		out.write(a.getBytes());
        		out.write("\n".getBytes());
        		BufferedReader reader = new BufferedReader(new InputStreamReader(fs.open(new Path(hdfsFilePath))));
        		while ((a = reader.readLine()) != null) {
                    out.write(a.getBytes());
                    out.write("\n".getBytes());
                }
        		IOUtils.closeStream(reader);
                IOUtils.closeStream(out);
                fs.delete(new Path(hdfsFilePath), true);
                fs.rename(new Path(hdfsFilePath.replace(".", "_mouthree" + ".")), new Path(hdfsFilePath));
                System.out.println("OK");
        	}else {
        		OutputStream out = fs.append(file_address);
        		System.out.println("input what you want add");
        		String a = scanner.nextLine();
        		out.write(a.getBytes());
        		out.write("\n".getBytes());
        		out.close();
        		System.out.println("OK");
        	}
        }else {
        	System.out.println("no file");
        }
        scanner.close();
	}
}
</code></pre>
<h3 id="流程-13"><a class="header" href="#流程-13">流程</a></h3>
<h3 id="实机演示-15"><a class="header" href="#实机演示-15">实机演示</a></h3>
<p><video controls src="HDFS_8.mp4" title="Title"></video></p>
<h3 id="代码详解-7"><a class="header" href="#代码详解-7"><a href="">代码详解</a></a></h3>
<hr />
<h2 id="9删除hdfs中指定的文件-1"><a class="header" href="#9删除hdfs中指定的文件-1"><code>(9)</code>删除HDFS中指定的文件</a></h2>
<pre><code class="language-java">
import java.util.Scanner;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;

public class nine {
	public static void main(String[] args) throws Exception {
		System.out.println("input hdfs file address");
		Scanner scanner = new Scanner(System.in);
		String hdfsFilePath = scanner.nextLine();
		Configuration conf = new Configuration();
		conf.set("fs.defaultFS","hdfs://localhost:9000");
        conf.set("fs.hdfs.impl","org.apache.hadoop.hdfs.DistributedFileSystem");
        conf.set("dfs.client.block.write.replace-datanode-on-failure.policy", "NEVER");
        conf.setBoolean("dfs.client.block.write.replace-datanode-on-failure.enable", true);
        FileSystem fs = FileSystem.get(conf);
        if(fs.exists(new Path(hdfsFilePath))) {
        	fs.delete(new Path(hdfsFilePath), true);
        	System.out.println("OK");
        }else {
        	System.out.println("no file");
        }
        scanner.close();
	}
}

</code></pre>
<h3 id="流程-14"><a class="header" href="#流程-14">流程</a></h3>
<h3 id="实机演示-16"><a class="header" href="#实机演示-16">实机演示</a></h3>
<p><video controls src="hdfs_9.mp4" title="Title"></video></p>
<h3 id="代码详解-8"><a class="header" href="#代码详解-8"><a href="">代码详解</a></a></h3>
<hr />
<h2 id="10删除hdfs中指定目录由用户指定目录中如果存在文件时是否删除目录-1"><a class="header" href="#10删除hdfs中指定目录由用户指定目录中如果存在文件时是否删除目录-1"><code>(10)</code>删除HDFS中指定目录，由用户指定目录中如果存在文件时是否删除目录</a></h2>
<pre><code class="language-java">import java.util.Scanner;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileStatus;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
public class ten {
	public static void main(String[] args) throws Exception {
		System.out.println("input hdfs file address");
		Scanner scanner = new Scanner(System.in);
		String hdfsFilePath = scanner.nextLine();
		Configuration conf = new Configuration();
		conf.set("fs.defaultFS","hdfs://localhost:9000");
        conf.set("fs.hdfs.impl","org.apache.hadoop.hdfs.DistributedFileSystem");
        conf.set("dfs.client.block.write.replace-datanode-on-failure.policy", "NEVER");
        conf.setBoolean("dfs.client.block.write.replace-datanode-on-failure.enable", true);
        FileSystem fs = FileSystem.get(conf);
        Path file_address = new Path(hdfsFilePath);
		if(fs.exists(new Path(hdfsFilePath))) {
    		FileStatus[] fileStatuses = fs.listStatus(file_address);
    		if(fileStatuses.length == 0) {
    			fs.delete(file_address, true);
    			System.out.println("successfully delete");
    		}else {
    			System.out.println("This folder is not empty, do you want to delete? (y/n)");
    			String t = scanner.nextLine();
    			if(t.equals("y")) {
    				fs.delete(file_address, true);
    				System.out.println("successfully delete");
    			}else {
    				System.out.println("OK");
    			}
    		}
    	}else {
    		System.out.println("no file");
    	}
		scanner.close();
	}
}
</code></pre>
<h3 id="流程-15"><a class="header" href="#流程-15">流程</a></h3>
<h3 id="实机演示-17"><a class="header" href="#实机演示-17">实机演示</a></h3>
<p>同第七题,直接输入要删除的文件夹名就行</p>
<h3 id="代码详解-9"><a class="header" href="#代码详解-9"><a href="">代码详解</a></a></h3>
<hr />
<h2 id="11在hdfs中将文件从源路径移动到目的路径-1"><a class="header" href="#11在hdfs中将文件从源路径移动到目的路径-1"><code>(11)</code>在HDFS中，将文件从源路径移动到目的路径</a></h2>
<pre><code class="language-java">import java.util.Scanner;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;

public class eleven {
	public static void main(String[] args) throws Exception {
		System.out.println("input hdfs file address");
		Scanner scanner = new Scanner(System.in);
		String hdfsFilePath = scanner.nextLine();
		System.out.println("input where you want move");
		String hdfsOverPath = scanner.nextLine();
		Configuration conf = new Configuration();
		conf.set("fs.defaultFS","hdfs://localhost:9000");
        conf.set("fs.hdfs.impl","org.apache.hadoop.hdfs.DistributedFileSystem");
        conf.set("dfs.client.block.write.replace-datanode-on-failure.policy", "NEVER");
        conf.setBoolean("dfs.client.block.write.replace-datanode-on-failure.enable", true);
        FileSystem fs = FileSystem.get(conf);
        Path file_address = new Path(hdfsFilePath);
        Path file_over_address = new Path(hdfsOverPath);
        if(fs.exists(file_address) &amp;&amp; fs.exists(file_over_address)) {
        	if(fs.rename(file_address, file_over_address)) {
        		System.out.println("successfully move");
        	}else {
        		System.out.println("ERROR");
        	}
        }else {
        	System.out.println("some folder is not in there");
        }
        scanner.close();
	}
}

</code></pre>
<h3 id="流程-16"><a class="header" href="#流程-16">流程</a></h3>
<h3 id="实机演示-18"><a class="header" href="#实机演示-18">实机演示</a></h3>
<p><video controls src="hdfs_11.mp4" title="Title"></video></p>
<h3 id="代码详解-10"><a class="header" href="#代码详解-10"><a href="">代码详解</a></a></h3>
<hr />
<h2 id="12实现按行读取一次返回一行如果空则返回-空"><a class="header" href="#12实现按行读取一次返回一行如果空则返回-空"><code>(12)</code>实现按行读取,一次返回一行,如果空则返回 "空"</a></h2>
<h3 id="注意该实验需要创建两个class"><a class="header" href="#注意该实验需要创建两个class">注意:该实验需要创建<code>两个</code>class</a></h3>
<h3 id="twelvejava的内容"><a class="header" href="#twelvejava的内容">twelve.java的内容</a></h3>
<pre><code class="language-java">import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import java.io.IOException;
import java.util.Scanner;

public class twelve {
	public static void main(String[] args) throws IOException {
		System.out.println("input hdfs file address");
		Scanner scanner = new Scanner(System.in);
		String hdfsFilePath = scanner.nextLine();
		Configuration conf = new Configuration();
		conf.set("fs.defaultFS","hdfs://localhost:9000");
        conf.set("fs.hdfs.impl","org.apache.hadoop.hdfs.DistributedFileSystem");
        conf.set("dfs.client.block.write.replace-datanode-on-failure.policy", "NEVER");
        conf.setBoolean("dfs.client.block.write.replace-datanode-on-failure.enable", true);
        FileSystem fs = FileSystem.get(conf);
        MyFSDataInputStream.cat(fs, hdfsFilePath);
        System.out.println("-----------------");
        System.out.println("");
        System.out.println("OK");
        scanner.close();
	}
}
</code></pre>
<h3 id="myfsdatainputstream的内容"><a class="header" href="#myfsdatainputstream的内容">MyFSDataInputStream的内容</a></h3>
<pre><code class="language-java">import org.apache.hadoop.fs.FSDataInputStream;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import java.io.*;

public class MyFSDataInputStream extends FSDataInputStream {

	public MyFSDataInputStream(InputStream in) {
		super(in);
		// TODO Auto-generated constructor stub
	}
	
	public static String readline(BufferedReader br) throws IOException {
		char[] data = new char[1024];
		int off = 0;
		while (br.read(data, off, 1) != -1) {
			if (String.valueOf(data[off]).equals("\n") ) {
				off += 1;
				break;
			}		
			off += 1;
		}
		if (off&gt; 0) {
			return String.valueOf(data);
		} else {
			return null;
		}
	}
	public static void cat(FileSystem fs, String FilePath) throws IOException {
		Path remotePath = new Path(FilePath);
		FSDataInputStream in = fs.open(remotePath);
		BufferedReader br = new BufferedReader(new InputStreamReader(in));
		String line = null;
		while ( (line = MyFSDataInputStream.readline(br)) != null ) {
			System.out.println(line);
		}
		br.close();
		in.close();
		fs.close();
	}
}
</code></pre>
<h3 id="流程-17"><a class="header" href="#流程-17">流程</a></h3>
<h3 id="实机演示-19"><a class="header" href="#实机演示-19">实机演示</a></h3>
<p><video controls src="hdfs_12.mp4" title="Title"></video></p>
<h3 id="代码详解-11"><a class="header" href="#代码详解-11"><a href="">代码详解</a></a></h3>
<hr />
<h2 id="13用javaneturl和orgapachehadoopfsfsurlstreamhandlerfactory编程完成输出hdfs中指定文件的文本到终端中"><a class="header" href="#13用javaneturl和orgapachehadoopfsfsurlstreamhandlerfactory编程完成输出hdfs中指定文件的文本到终端中"><code>(13)</code>用<code>java.net.URL</code>和<code>org.apache.hadoop.fs.FsURLStreamHandlerFactory</code>编程完成输出HDFS中指定文件的文本到终端中</a></h2>
<pre><code class="language-java">import java.io.IOException;
import java.util.Scanner;
import java.net.URL;
import org.apache.hadoop.conf.Configuration;
import java.io.InputStream;
import org.apache.hadoop.io.IOUtils;
import org.apache.hadoop.fs.FsUrlStreamHandlerFactory;

public class thirteen {
	static{
        URL.setURLStreamHandlerFactory(new FsUrlStreamHandlerFactory());
    }
	public static void main(String[] args) throws IOException {
		System.out.println("input hdfs file address");
		Scanner scanner = new Scanner(System.in);
		String hdfsFilePath = scanner.nextLine();
		Configuration conf = new Configuration();
		conf.set("fs.defaultFS","hdfs://localhost:9000");
        conf.set("fs.hdfs.impl","org.apache.hadoop.hdfs.DistributedFileSystem");
        conf.set("dfs.client.block.write.replace-datanode-on-failure.policy", "NEVER");
        conf.setBoolean("dfs.client.block.write.replace-datanode-on-failure.enable", true);
        InputStream in = new URL("hdfs://localhost:9000" + hdfsFilePath).openStream();
        IOUtils.copyBytes(in, System.out, 2048,false);
        IOUtils.closeStream(in);
        scanner.close();
        System.out.println("-----------------");
        System.out.println("");
        System.out.println("OK");
	}
}
</code></pre>
<h3 id="流程-18"><a class="header" href="#流程-18">流程</a></h3>
<h3 id="实机演示-20"><a class="header" href="#实机演示-20">实机演示</a></h3>
<p><video controls src="hdfs_13.mp4" title="Title"></video></p>
<h3 id="代码详解-12"><a class="header" href="#代码详解-12"><a href="">代码详解</a></a></h3>
<hr />
<hr />
<h1 id="附录一--一些基础操作"><a class="header" href="#附录一--一些基础操作">附录一 : 一些基础操作</a></h1>
<h2 id="关于如何创建hdfs项目"><a class="header" href="#关于如何创建hdfs项目">关于如何创建HDFS项目</a></h2>
<p>在进入eclipse之后,按照如下视频操作</p>
<p><video controls src="java_f_1.mp4" title="Title"></video></p>
<p>实验几,命名就叫几,例如实验二, 项目名字叫<code>HDFS_2</code>, 类名叫<code>two</code></p>
<hr />
<hr />
<h1 id="附录二--代码逻辑分析"><a class="header" href="#附录二--代码逻辑分析">附录二 : 代码逻辑分析</a></h1>
<h2 id="1"><a class="header" href="#1">1</a></h2>
<hr />
<h2 id="2"><a class="header" href="#2">2</a></h2>
<hr />
<h2 id="3"><a class="header" href="#3">3</a></h2>
<hr />
<h2 id="4"><a class="header" href="#4">4</a></h2>
<hr />
<h2 id="5"><a class="header" href="#5">5</a></h2>
<hr />
<h2 id="6"><a class="header" href="#6">6</a></h2>
<hr />
<h2 id="7"><a class="header" href="#7">7</a></h2>
<hr />
<h2 id="8"><a class="header" href="#8">8</a></h2>
<hr />
<h2 id="9"><a class="header" href="#9">9</a></h2>
<hr />
<h2 id="10"><a class="header" href="#10">10</a></h2>
<hr />
<h2 id="11"><a class="header" href="#11">11</a></h2>
<hr />
<h2 id="12"><a class="header" href="#12">12</a></h2>
<hr />
<h2 id="13"><a class="header" href="#13">13</a></h2>
<hr />

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </div>
    </body>
</html>
